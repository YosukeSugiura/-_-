{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNybhI//PMwzBg9i5gw5Zgy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YosukeSugiura/-_-/blob/main/%E6%BC%94%E7%BF%92%E8%AA%B2%E9%A1%8C%EF%BC%91%EF%BC%9AWorld%E3%81%AB%E3%82%88%E3%82%8B%E5%A3%B0%E8%B3%AA%E5%A4%89%E6%8F%9B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGSkE25Q8uYt"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Voice_Conversion_experiments_online_demo.ipynb\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "# Voice Conversion (Teaching Notebook)\n",
        "\n",
        "**Created:** 2025-09-28\n",
        "**Author:** Yosuke Sugiura (Saitama University)\n",
        "**Purpose:** Hands-on exercise on voice conversion using WORLD (Pitch/Formant/Aperiodicity) in Google Colab.\n",
        "**Audience:** Undergraduate/Graduate audio/speech class\n",
        "**Notes:** Tested on Colab (Python 3.12), Gradio 5.7.x, librosa 0.10.2.post1, pyworld 0.3.4.\n",
        "\"\"\"\n",
        "\n",
        "# =========================\n",
        "# Setup (Colab)\n",
        "# =========================\n",
        "# Base build tools\n",
        "!pip -q install -U pip setuptools wheel\n",
        "!pip -q install -U soxr>=0.3.7\n",
        "\n",
        "# NumPy pinned to satisfy TF (<2.2) & numba (<2.1), and keep OpenCV happy (>=2)\n",
        "!pip -q install -U \"numpy==2.0.2\"\n",
        "\n",
        "# Audio stack\n",
        "!pip -q install -U librosa==0.10.2.post1 soundfile==0.12.1 pyworld==0.3.4\n",
        "\n",
        "# Gradio 5.x (includes updated client); websockets >=14 to satisfy other libs too\n",
        "!pip -q install -U \"gradio==5.47.2\" \"websockets>=14,<16\"\n",
        "\n",
        "# 日本語フォント（図の日本語表示用）\n",
        "!apt-get -y -qq install fonts-ipafont-gothic > /dev/null\n",
        "\n",
        "# =========================\n",
        "# Cell 2 — Core functions\n",
        "# =========================\n",
        "# WORLD-based voice conversion with:\n",
        "# - Pitch (F0) shift in semitones\n",
        "# - Formant shift via Mel-scale spectral-envelope warping\n",
        "# - Aperiodicity control (single slider: breathiness b)\n",
        "# - Robust loader: decode at native SR, resample to 24 kHz only if needed\n",
        "\n",
        "import numpy as np\n",
        "import librosa, soundfile as sf\n",
        "import pyworld as pw\n",
        "import matplotlib\n",
        "matplotlib.rcParams[\"font.family\"] = \"IPAGothic\"   # 日本語フォント\n",
        "matplotlib.rcParams[\"axes.unicode_minus\"] = False  # マイナス記号対策\n",
        "\n",
        "SR = 24000  # working sample rate for WORLD\n",
        "\n",
        "def _f64c(x):\n",
        "    \"\"\"Make array float64 & C-contiguous (pyworld is strict).\"\"\"\n",
        "    return np.ascontiguousarray(x, dtype=np.float64)\n",
        "\n",
        "def load_wav(path, target_sr=SR, do_trim=False):\n",
        "    \"\"\"\n",
        "    Load audio at its native sample rate, then resample to target_sr only if needed.\n",
        "    Optionally trim leading/trailing silence (disabled by default).\n",
        "    \"\"\"\n",
        "    y, sr_in = librosa.load(path, sr=None, mono=True)  # decode at native SR\n",
        "    if do_trim:\n",
        "        y, _ = librosa.effects.trim(y, top_db=30)\n",
        "    if sr_in != target_sr:\n",
        "        y = librosa.resample(y, orig_sr=sr_in, target_sr=target_sr, res_type=\"soxr_hq\")\n",
        "    y = librosa.util.normalize(y)\n",
        "    return _f64c(y), target_sr\n",
        "\n",
        "def world_analyze(x, sr):\n",
        "    \"\"\"WORLD analysis: F0 (harvest), spectral envelope (cheaptrick), aperiodicity (d4c).\"\"\"\n",
        "    x = _f64c(x)\n",
        "    f0, t = pw.harvest(x, sr, f0_floor=50.0, f0_ceil=600.0)\n",
        "    sp = pw.cheaptrick(x, f0, t, sr)   # [n_frame, n_bin], linear-freq envelope\n",
        "    ap = pw.d4c(x, f0, t, sr)          # [n_frame, n_bin], 0..1\n",
        "    return _f64c(f0), _f64c(sp), _f64c(ap), t\n",
        "\n",
        "def world_synthesize(f0, sp, ap, sr):\n",
        "    \"\"\"WORLD synthesis with guards and peak normalization.\"\"\"\n",
        "    f0 = _f64c(f0); sp = _f64c(sp); ap = _f64c(ap)\n",
        "    # Replace bad values if any\n",
        "    if not np.isfinite(f0).all(): f0 = np.nan_to_num(f0, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "    if not np.isfinite(sp).all(): sp = np.nan_to_num(sp, nan=1e-6, posinf=1.0, neginf=1e-6)\n",
        "    if not np.isfinite(ap).all(): ap = np.nan_to_num(ap, nan=0.0, posinf=1.0, neginf=0.0)\n",
        "    y = pw.synthesize(f0, sp, ap, sr)\n",
        "    peak = float(np.max(np.abs(y)) + 1e-9)\n",
        "    return (y / peak).astype(np.float32)\n",
        "\n",
        "def _spec_image_path_from_audio(y, sr, title=\"スペクトログラム\"):\n",
        "    \"\"\"Create and save a spectrogram PNG from waveform y. Returns file path (PNG).\"\"\"\n",
        "    try:\n",
        "        import matplotlib\n",
        "        matplotlib.use(\"Agg\")\n",
        "        import matplotlib.pyplot as plt\n",
        "        import librosa\n",
        "        import librosa.display as lbd\n",
        "        import numpy as np\n",
        "        import tempfile\n",
        "\n",
        "        # STFT magnitude -> dB\n",
        "        D = np.abs(librosa.stft(y, n_fft=1024, hop_length=256, win_length=1024))\n",
        "        Db = librosa.amplitude_to_db(D, ref=np.max)\n",
        "\n",
        "        fig = plt.figure(figsize=(8, 3))\n",
        "        ax = fig.add_subplot(111)\n",
        "        lbd.specshow(Db, sr=sr, hop_length=256, x_axis=\"time\", y_axis=\"linear\", ax=ax)\n",
        "        ax.set_title(title)\n",
        "        ax.set_xlabel(\"時間 [s]\")\n",
        "        ax.set_ylabel(\"周波数 [Hz]\")\n",
        "        fig.tight_layout()\n",
        "\n",
        "        tmp = tempfile.NamedTemporaryFile(delete=False, suffix=\".png\")\n",
        "        fig.savefig(tmp.name, dpi=150)\n",
        "        plt.close(fig)\n",
        "        return tmp.name\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def shift_pitch(f0, semitone):\n",
        "    \"\"\"Shift F0 by semitones (unvoiced frames stay at 0).\"\"\"\n",
        "    ratio = 2.0 ** (semitone / 12.0)\n",
        "    f0_new = f0.copy()\n",
        "    mask = f0_new > 0.0\n",
        "    f0_new[mask] *= ratio\n",
        "    return _f64c(f0_new)\n",
        "\n",
        "# ----- Mel utilities -----\n",
        "def hz2mel(f):  return 2595.0 * np.log10(1.0 + f / 700.0)\n",
        "def mel2hz(m):  return 700.0 * (10.0**(m / 2595.0) - 1.0)\n",
        "\n",
        "def warp_spectral_envelope_mel(sp, sr, formant_ratio, tilt_db_per_oct=0.0):\n",
        "    \"\"\"\n",
        "    Formant shifting by warping WORLD spectral envelope along the Mel axis.\n",
        "    * Interpolate in log-amplitude to preserve shapes.\n",
        "    * Per-frame power normalization to avoid overall timbre drift.\n",
        "    * tilt_db_per_oct は授業簡略化のため 0 固定で利用。\n",
        "    \"\"\"\n",
        "    sp = _f64c(sp)\n",
        "    nframe, nbin = sp.shape\n",
        "    f_lin = np.linspace(0.0, sr/2, nbin)\n",
        "    f_safe = np.maximum(f_lin, 20.0)\n",
        "    m_lin = hz2mel(f_safe)\n",
        "\n",
        "    m_src = m_lin / max(float(formant_ratio), 1e-6)\n",
        "    f_src = mel2hz(m_src)\n",
        "\n",
        "    pos = np.clip(f_src / (sr/2) * (nbin - 1), 0, nbin - 1)\n",
        "    lo = np.floor(pos).astype(int)\n",
        "    hi = np.clip(lo + 1, 0, nbin - 1)\n",
        "    w  = (pos - lo)[None, :]\n",
        "\n",
        "    logsp = np.log(np.maximum(sp, 1e-12))\n",
        "    logsp_warp = (1 - w) * logsp[:, lo] + w * logsp[:, hi]\n",
        "    sp_warp = np.exp(logsp_warp)\n",
        "\n",
        "    if abs(tilt_db_per_oct) > 1e-6:\n",
        "        ref = 1000.0\n",
        "        ratio = np.maximum(f_safe / ref, 1e-6)\n",
        "        gain = 10.0 ** ((tilt_db_per_oct * np.log2(ratio)) / 20.0)\n",
        "        sp_warp *= gain[None, :]\n",
        "\n",
        "    src_pow = np.sum(sp, axis=1, keepdims=True) + 1e-9\n",
        "    dst_pow = np.sum(sp_warp, axis=1, keepdims=True) + 1e-9\n",
        "    sp_warp *= (src_pow / dst_pow)\n",
        "    return _f64c(sp_warp)\n",
        "\n",
        "# --- 非周期性（息っぽさ）b：ロジット1本化 ---\n",
        "def adjust_aperiodicity_unified(ap, b, k=2.0):\n",
        "    ap = np.clip(ap, 1e-6, 1-1e-6)\n",
        "    logit = np.log(ap/(1-ap))\n",
        "    ap2 = 1.0/(1.0 + np.exp(-(logit + k*b)))\n",
        "    return np.clip(ap2, 0.0, 1.0)\n",
        "\n",
        "def match_stats_to_target_mel(f0_src, sp_src, f0_tgt, sp_tgt, sr):\n",
        "    \"\"\"Rough target-guided alignment: median F0 + Mel spectral centroid (not used in UI).\"\"\"\n",
        "    nz_src = f0_src[f0_src > 1.0]\n",
        "    nz_tgt = f0_tgt[f0_tgt > 1.0]\n",
        "    semi = 12*np.log2(np.median(nz_tgt)/np.median(nz_src)) if (len(nz_src) and len(nz_tgt)) else 0.0\n",
        "\n",
        "    def mel_centroid(sp, sr):\n",
        "        f = np.linspace(0, sr/2, sp.shape[1]); f = np.maximum(f, 20.0)\n",
        "        m = hz2mel(f); vals = []\n",
        "        for S in sp:\n",
        "            w = S + 1e-9\n",
        "            vals.append((m*w).sum()/w.sum())\n",
        "        return float(np.median(vals))\n",
        "\n",
        "    c_src = mel_centroid(sp_src, sr)\n",
        "    c_tgt = mel_centroid(sp_tgt, sr)\n",
        "    formant_ratio = float(np.clip(c_tgt/max(c_src,1e-9), 0.6, 1.8))\n",
        "    return float(semi), formant_ratio\n",
        "\n",
        "# =========================\n",
        "# Cell 1 — Reset server\n",
        "# =========================\n",
        "# Prevent event-loop conflicts on re-run in Colab.\n",
        "import gradio as gr\n",
        "try:\n",
        "    gr.close_all()\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# =========================\n",
        "# Cell 3 — Gradio UI (label → hint → slider; no Target; URL only)\n",
        "# =========================\n",
        "import gradio as gr\n",
        "import tempfile, os, traceback, json\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "\n",
        "def _to_path(obj):\n",
        "    if obj is None:\n",
        "        return None\n",
        "    if isinstance(obj, (str, os.PathLike)):\n",
        "        return str(obj)\n",
        "    if isinstance(obj, dict) and \"name\" in obj:\n",
        "        return obj[\"name\"]\n",
        "    if isinstance(obj, (list, tuple)) and len(obj) > 0:\n",
        "        v = obj[0]\n",
        "        if isinstance(v, (str, os.PathLike)):\n",
        "            return str(v)\n",
        "        if isinstance(v, dict) and \"name\" in v:\n",
        "            return v[\"name\"]\n",
        "    raise ValueError(\"Unsupported audio object from UI.\")\n",
        "\n",
        "def process(source_audio, pitch_semitone, formant_ratio, breathiness_b):\n",
        "    try:\n",
        "        src_path = _to_path(source_audio)\n",
        "        if not (src_path and os.path.exists(src_path)):\n",
        "            return None, \"入力音声を読み込めませんでした。録音またはファイルを指定してください。\", None, None\n",
        "\n",
        "        x, sr = load_wav(src_path, SR)\n",
        "        if len(x) < int(0.3 * SR):\n",
        "            return None, \"音声が短すぎます（0.5秒以上を推奨）。\", None, None\n",
        "\n",
        "        # WORLD解析\n",
        "        f0, sp, ap, _ = world_analyze(x, sr)\n",
        "\n",
        "        # 変換（ピッチ／フォルマント／非周期性=統一スライダ）\n",
        "        f0_m = shift_pitch(f0, pitch_semitone)\n",
        "        sp_m = warp_spectral_envelope_mel(sp, sr, formant_ratio, tilt_db_per_oct=0.0)  # 傾きは固定0\n",
        "        ap_m = adjust_aperiodicity_unified(ap, b=float(breathiness_b), k=2.0)\n",
        "\n",
        "        y = world_synthesize(f0_m, sp_m, ap_m, sr)\n",
        "\n",
        "        # WAV保存（変換後）\n",
        "        import tempfile\n",
        "        tmp = tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\")\n",
        "        sf.write(tmp.name, y, sr)\n",
        "\n",
        "        info = (\n",
        "            f\"ピッチ: {pitch_semitone:+.1f} semitone｜\"\n",
        "            f\"フォルマント比(Mel): ×{formant_ratio:.2f}｜\"\n",
        "            f\"非周期性（息っぽさ）b: {breathiness_b:+.2f}\"\n",
        "        )\n",
        "\n",
        "        # スペクトログラム（前・後）\n",
        "        spec_src  = _spec_image_path_from_audio(x, sr, title=\"スペクトログラム（変換前）\")\n",
        "        spec_conv = _spec_image_path_from_audio(y, sr, title=\"スペクトログラム（変換後）\")\n",
        "\n",
        "        return tmp.name, info, spec_src, spec_conv\n",
        "\n",
        "    except Exception:\n",
        "        import traceback\n",
        "        return None, f\"**エラー**\\n\\n```traceback\\n{traceback.format_exc()}\\n```\", None, None\n",
        "\n",
        "# 原音（録音そのまま）をWAVで保存するヘルパ\n",
        "def _save_original(source_audio):\n",
        "    try:\n",
        "        src_path = _to_path(source_audio)\n",
        "        if not (src_path and os.path.exists(src_path)):\n",
        "            return None\n",
        "        y, sr = sf.read(src_path)\n",
        "        if y.ndim > 1:\n",
        "            y = y[:, 0]\n",
        "        tmp = tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\")\n",
        "        sf.write(tmp.name, y, sr)\n",
        "        return tmp.name\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## WORLDベース音声変換（Melスケール・フォルマントワープ）\")\n",
        "    gr.Markdown(\"短い**話し声**を録音／アップロードし、スライダを調整して**変換**を押してください。最下部に**変換前／変換後**のスペクトログラムが**横並び**で表示されます。\")\n",
        "\n",
        "    # UI微調整：×(Clear)ボタンを隠す\n",
        "    gr.HTML(\"\"\"\n",
        "    <style>\n",
        "      button[aria-label=\"Clear\"] { display: none !important; }  /* Audioの×ボタン非表示 */\n",
        "      .param-title { font-weight:600; margin:8px 0 2px; }\n",
        "      .param-hint  { font-size:0.85rem; color:#6b7280; margin:0 0 6px; }\n",
        "    </style>\n",
        "    \"\"\")\n",
        "\n",
        "    # 入力音声\n",
        "    src = gr.Audio(sources=[\"microphone\",\"upload\"], type=\"filepath\",\n",
        "                   label=\"入力音声（自分の声）\",\n",
        "                   waveform_options={\"show_recording_waveform\": True})\n",
        "\n",
        "    # その場で即ダウンロード開始（1クリック）\n",
        "    save_dl = gr.DownloadButton(\"原音WAVをダウンロード\", variant=\"primary\")\n",
        "\n",
        "    def _save_original(ui_audio):\n",
        "        try:\n",
        "            src_path = _to_path(ui_audio)\n",
        "            if not (src_path and os.path.exists(src_path)):\n",
        "                return None  # 未選択ならダウンロードは発火しない\n",
        "            y, sr = sf.read(src_path)\n",
        "            if y.ndim > 1:\n",
        "                y = y[:, 0]\n",
        "            tmp = tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\")\n",
        "            sf.write(tmp.name, y, sr)\n",
        "            return tmp.name  # DownloadButton の value に渡る → 直後に保存ダイアログ\n",
        "        except Exception:\n",
        "            return None\n",
        "\n",
        "    # DownloadButton 自身を outputs に指定して value を更新＝即ダウンロード\n",
        "    save_dl.click(_save_original, inputs=[src], outputs=[save_dl])\n",
        "\n",
        "    # スライダ群\n",
        "    gr.HTML(\"<div class='param-title'>ピッチ（semitone）</div>\"\n",
        "            \"<div class='param-hint'>上げる→高く若め／下げる→低く落ち着き</div>\")\n",
        "    pitch = gr.Slider(-12, 12, value=0.0, step=0.1, label=\"\", show_label=False)\n",
        "\n",
        "    gr.HTML(\"<div class='param-title'>フォルマント比（Mel）</div>\"\n",
        "            \"<div class='param-hint'>1.0より大→明るめ・子ども声寄り／1.0より小→暗め・大人声寄り</div>\")\n",
        "    formant = gr.Slider(0.6, 1.8, value=1.00, step=0.01, label=\"\", show_label=False)\n",
        "\n",
        "    gr.HTML(\"<div class='param-title'>非周期性（息っぽさ） b</div>\"\n",
        "            \"<div class='param-hint'>-1でクリア／+1で息多め（推奨 ±0.6）</div>\")\n",
        "    breath = gr.Slider(-1.0, 1.0, value=0.0, step=0.05, label=\"\", show_label=False)\n",
        "\n",
        "    # 実行と出力\n",
        "    btn = gr.Button(\"変換\")\n",
        "    out_audio = gr.Audio(label=\"変換後音声\")  # 右上に標準のダウンロードボタンあり\n",
        "    out_text  = gr.Markdown()                # 簡潔情報のみ（デバッグ非表示）\n",
        "    with gr.Row():\n",
        "        out_spec_src  = gr.Image(label=\"スペクトログラム（変換前）\", type=\"filepath\")\n",
        "        out_spec_conv = gr.Image(label=\"スペクトログラム（変換後）\", type=\"filepath\")\n",
        "\n",
        "    btn.click(process, inputs=[src, pitch, formant, breath],\n",
        "              outputs=[out_audio, out_text, out_spec_src, out_spec_conv])\n",
        "\n",
        "# Launch without inline iframe; print URL only\n",
        "demo.queue()\n",
        "res = demo.launch(share=True, inline=False, debug=False, show_error=True)\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output(wait=True)\n",
        "url = getattr(res, \"share_url\", None) or getattr(res, \"public_url\", None)\n",
        "if url is None:\n",
        "    try:\n",
        "        _, _, url = res\n",
        "    except Exception:\n",
        "        url = \"(no share URL)\"\n",
        "\n",
        "# --- Show only URL + QR in Colab output ---\n",
        "from IPython.display import clear_output, display, Markdown, Image\n",
        "clear_output(wait=True)\n",
        "\n",
        "# Get public URL safely across gradio versions\n",
        "url = getattr(res, \"share_url\", None) or getattr(res, \"public_url\", None)\n",
        "if url is None:\n",
        "    try:\n",
        "        _, _, url = res  # older tuple return\n",
        "    except Exception:\n",
        "        url = None\n",
        "\n",
        "if not url:\n",
        "    print(\"No share URL.\")\n",
        "else:\n",
        "    # install a tiny QR lib (pure-Python)\n",
        "    try:\n",
        "        import segno\n",
        "    except Exception:\n",
        "        import sys, subprocess\n",
        "        subprocess.run([sys.executable, \"-m\", \"pip\", \"-q\", \"install\", \"segno\"], check=False)\n",
        "        import segno\n",
        "\n",
        "    qr_path = \"/content/gradio_url_qr.png\"\n",
        "    segno.make(url).save(qr_path, scale=8, border=2)  # scaleでサイズ調整\n",
        "\n",
        "    display(Markdown(f\"### Public URL\\n**{url}**\"))\n",
        "    display(Image(qr_path))\n",
        "    #print(\"QR saved:\", qr_path)\n"
      ]
    }
  ]
}